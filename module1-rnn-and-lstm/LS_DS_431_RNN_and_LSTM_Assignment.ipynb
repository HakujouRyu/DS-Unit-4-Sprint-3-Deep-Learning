{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-17 00:38:13--  https://www.gutenberg.org/files/100/100-0.txt\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5777367 (5.5M) [text/plain]\n",
      "Saving to: ‘100-0.txt.1’\n",
      "\n",
      "100-0.txt.1         100%[===================>]   5.51M  9.51MB/s    in 0.6s    \n",
      "\n",
      "2019-12-17 00:38:14 (9.51 MB/s) - ‘100-0.txt.1’ saved [5777367/5777367]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO - Words, words, mere words, no matter from the heart.\n",
    "!wget \"https://www.gutenberg.org/files/100/100-0.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('100-0.txt', 'r')\n",
    "data = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "cleandata = re.sub(r'[^a-zA-Z ^0-9]', '', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Project Gutenbergs The Complete Works of William Shakespeare by WilliamShakespeareThis eBook is for '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleandata[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cleandata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list of unique characters\n",
    "chars = list(set(cleandata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G', '2', 'C', 'h', 'W', 'i', 'Y', 'J', 'b', 'E']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make char lookups\n",
    "char_int = {c:i for i,c in enumerate(chars)}\n",
    "int_char = {i:c for i,c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequnces len 513396\n"
     ]
    }
   ],
   "source": [
    "#sequence the data\n",
    "maxlen = 80\n",
    "step = 10\n",
    "\n",
    "encoded = [char_int[c] for c in cleandata]\n",
    "\n",
    "sequences = [] #lists of sequnces the length of maxlen\n",
    "next_chars = [] # lists of 1 char length\n",
    "\n",
    "for i in range(0, len(encoded) - maxlen, step):\n",
    "    sequences.append(encoded[i: i + maxlen])\n",
    "    next_chars.append(encoded[i + maxlen])\n",
    "print('sequnces len', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up shapes \n",
    "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i,sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i,t,char] = 1\n",
    "    y[i, next_chars[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513396, 80, 63)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128,input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "optimizer = RMSprop(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COPIED FROM LECTURE\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from lecture\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, np.absolute(len(cleandata) - maxlen - 1))\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = cleandata[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_int[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = int_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "513024/513396 [============================>.] - ETA: 1s - loss: 1.9979\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" by treasonsDo botch and bungle up damnationWith patches colours and with forms \"\n",
      " by treasonsDo botch and bungle up damnationWith patches colours and with forms stood the so the seart the start in the speat he with the bet the of the sist the starn the good the come the stard the with the sance    The with the so the sure the to me the for the bet the sting the sear the sear of the sing the sain the stord the reart and the ser with the come to the sting the sting the lord the come    And the starn the the for the stord the to the sure the start the sull t\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" by treasonsDo botch and bungle up damnationWith patches colours and with forms \"\n",
      " by treasonsDo botch and bungle up damnationWith patches colours and with forms will come of the fard me The bets mid me proods his brangs that good in the will you lids his trought and more her such to the fad the sear and and the dows as the and at and the betian she with a dive so fall mant the sive the daigher stis thou her the leas in the serse in her and so be that the that list the kead to that sen the sure the ser aw and stond the the to part the earst hear so conter \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" by treasonsDo botch and bungle up damnationWith patches colours and with forms \"\n",
      " by treasonsDo botch and bungle up damnationWith patches colours and with forms I evan the good Do thou wors apperst be lith of liokeTI Prapint and this cenres of pliegend cembard tis morkeer a thy lecks whe I kel hath his fouse eldfere wo way ma haster sad ant shar OntoreTheed and cemsGadnd wan stork  SUINGASTA lys    As will you fils ot me of the buethTe felldHy harvis pivenit madpem if Thy heart doad geans the ry lave us for therse shall majusmy foverst If the ear ivels Ra\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" by treasonsDo botch and bungle up damnationWith patches colours and with forms \"\n",
      " by treasonsDo botch and bungle up damnationWith patches colours and with forms Lard comusnire ButEOMERSUCTha banut of aUGALENISTo hay nis withans shem withtrup to legstHave ney servalgs is ay doundfel of It lolkPaltes onees abn the sintLeAnd camickIIUTORISGaky  FTOLIIA TeunrESORMUSquoncengy dass I winhsem blaydch in stryay bedCholous VabeerempofusVAMONI will Hayreat his myThy losk  S icbukents he ell aad    Dis it the govh DUais  ETRCOBROSN youThou wyeds    And Efull eiase  \n",
      "513396/513396 [==============================] - 1432s 3ms/sample - loss: 1.9980\n",
      "Epoch 2/5\n",
      "513024/513396 [============================>.] - ETA: 1s - loss: 1.9100\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"n or a lovers luteFALSTAFFYea or the drone of a Lincolnshire bagpipePRINCEWhat s\"\n",
      "n or a lovers luteFALSTAFFYea or the drone of a Lincolnshire bagpipePRINCEWhat so make the come and the sure he mather the will the have and the shall shall my love in the so will not to me with the have he wall be the so me the with the sour and the hear a more of the some a man the with the word the have the have the tour the have he will the for the sould the will and the sear the have the come and seave the with the for the sould he wath the seave the come to me the love \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"n or a lovers luteFALSTAFFYea or the drone of a Lincolnshire bagpipePRINCEWhat s\"\n",
      "n or a lovers luteFALSTAFFYea or the drone of a Lincolnshire bagpipePRINCEWhat stould in the hearts of it god to and my so                                                                                                                                                               Enter SENAS SANG And and that the wort                                                                                                                                                                 \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"n or a lovers luteFALSTAFFYea or the drone of a Lincolnshire bagpipePRINCEWhat s\"\n",
      "n or a lovers luteFALSTAFFYea or the drone of a Lincolnshire bagpipePRINCEWhat so pare    Make one trute you ir I ap gaynime Glefor that he propsom and wall ot me teend a ite ay IfferchCUFYRUSIf netwer what of Ruce to nome at me me tumie Luscot of to medierty sumBBURIBUSIf if Nouch Yo dokince and I id on Feringar To GaAnAAGher my pingland ver comferroverTo hear and you my lord his sase comeans FrightWhich man you arverere have paswed pold thou housh live oor fead ane batour G\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"n or a lovers luteFALSTAFFYea or the drone of a Lincolnshire bagpipePRINCEWhat s\"\n",
      "n or a lovers luteFALSTAFFYea or the drone of a Lincolnshire bagpipePRINCEWhat surciume celvot and pursefortaAd no Simstrebuece will thy theck morly  IBe opoftion negiond he foul ore Lladply efed lostell gah for the the salfBe thougakmentres ah mashay the him oDr QuenneDIUNHIODUEY JORCHZwathersabpers you she cobfices thees Gle gam toVEJLID wave to do gree and gund myLiketAN  CI folloulute paosonCANOOLey ventionNUSHIADGHevir by I stithIwlrtherobwer soobst fith then putsdond of\n",
      "513396/513396 [==============================] - 1476s 3ms/sample - loss: 1.9099\n",
      "Epoch 3/5\n",
      "513024/513396 [============================>.] - ETA: 0s - loss: 1.8466\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"s are open let us enter too  KING EDWARD So other foes may set upon our backs   \"\n",
      "s are open let us enter too  KING EDWARD So other foes may set upon our backs    The good                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"s are open let us enter too  KING EDWARD So other foes may set upon our backs   \"\n",
      "s are open let us enter too  KING EDWARD So other foes may set upon our backs    The swould with the graten the hand the king in were                                                                                                                                                                                                                                                                                                                                                           \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"s are open let us enter too  KING EDWARD So other foes may set upon our backs   \"\n",
      "s are open let us enter too  KING EDWARD So other foes may set upon our backs                              Dentigha anauth coutief umder praysh this chomy  SIANBURWA Hor Cranal of nofe foe that to mould    And good my ippan    Aad leaved whichsenged  YLATHEHO  Loung to For a brants and CRVALE I chanding souls speck her east  spectipeth han in there anscliend stive he pAat leck the hey brams toke hime trief me Expiss Ils nave Buckd have Your had no him this all our cotSliOWCOL\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"s are open let us enter too  KING EDWARD So other foes may set upon our backs   \"\n",
      "s are open let us enter too  KING EDWARD So other foes may set upon our backs    SumESRENTER at ructTo colierFouncbet I mels the maguio MRSHOMULUT Is that stalg mystLOUCIUSTagain ICrovinight WouldLERIAMYourswAck mear taik heacusANTO Alank breamild  A Tay some WathayDRSSNUZOTHky lut dearnensel  ItScyEVISULWhat Nay capmone Let ame hath tould suld atrABFOLANII head hemenould fatced eads ton Giveayod UflloYAtooe thesTlen thou gotWhe Aar bounds thrig ligsfend EButter moulyFLadSERE\n",
      "513396/513396 [==============================] - 1447s 3ms/sample - loss: 1.8466\n",
      "Epoch 4/5\n",
      "429056/513396 [========================>.....] - ETA: 3:47 - loss: 1.8003"
     ]
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=512,\n",
    "          epochs=5,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
